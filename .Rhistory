library(mlr3misc)
library(paradox)
# 读取数据
df <- read.csv("/Users/benrio0923/Documents/計畫專案/NeuA ana/test/data.csv",
header = TRUE, sep = ',', encoding = 'UTF-8')
# 假設數據存儲在 df 中，其中 "NT" 是目標變量，"S1" 和 "RBD" 是特徵
task <- TaskRegr$new(id = "nt_task", backend = df, target = "NT")
# 定義多個回歸模型（包含隨機森林、SVM、線性回歸、XGBoost 和 Elastic Net）
learner_rf <- lrn("regr.ranger")        # 隨機森林
learner_svm <- lrn("regr.svm")          # 支持向量機
learner_lm <- lrn("regr.lm")            # 線性回歸
learner_xgb <- lrn("regr.xgboost")      # XGBoost
learner_glmnet <- lrn("regr.glmnet")    # Elastic Net
# 定義每個模型的超參數搜索空間
param_rf <- ParamSet$new(list(
ParamInt$new("mtry", lower = 1, upper = length(task$feature_names)),
ParamInt$new("min.node.size", lower = 1, upper = 10)
))
library(paradox)
# 加載必要的庫
library(caret)
# 读取数据
df <- read.csv("/Users/benrio0923/Documents/計畫專案/NeuA ana/test/data.csv",
header = TRUE, sep = ',', encoding = 'UTF-8')
x <- data[, c("S1", "RBD")]  # 特徵變量
View(df)
# 加載必要的庫
library(caret)
# 读取数据
data <- read.csv("/Users/benrio0923/Documents/計畫專案/NeuA ana/test/data.csv",
header = TRUE, sep = ',', encoding = 'UTF-8')
x <- data[, c("S1", "RBD")]  # 特徵變量
y <- data$NT  # 目標變量
# 訓練控制，使用10折交叉驗證，並設置評估指標為 R-squared
control <- trainControl(method = "cv", number = 10, summaryFunction = defaultSummary)
# 搜索所有可用的回歸模型
models <- c("lm", "rpart", "rf", "svmRadial", "knn", "ridge", "lasso", "xgbLinear", "gbm")
# 創建一個列表來存儲每個模型的結果
model_list <- list()
# 循環訓練每個模型，並同時調整超參數
for (model in models) {
print(paste("Training model:", model))
# 使用 tuneLength 設定進行自動調參
model_train <- train(x, y,
method = model,
trControl = control,
tuneLength = 10,  # 搜索最佳超參數
metric = "Rsquared")  # 使用 R-squared 作為評估指標
model_list[[model]] <- model_train
}
# 比較所有模型的結果
results <- resamples(model_list)
summary(results)
# 圖形化比較
dotplot(results)
#---------------------------------------------------------------------------------------------
# 檢查最佳的模型參數
for (model in names(model_list)) {
print(paste("Best parameters for model:", model))
print(model_list[[model]]$bestTune)
}
# 查看 R-squared 最高的模型
best_model <- model_list[[which.max(sapply(model_list, function(x) max(x$results$Rsquared)))]]
print(best_model)
# 使用最佳模型進行預測
predictions <- predict(best_model, newdata = x)
# 加載必要的庫
library(caret)
# 读取数据
data <- read.csv("/Users/benrio0923/Documents/計畫專案/NeuA ana/test/data.csv",
header = TRUE, sep = ',', encoding = 'UTF-8')
x <- data[, c("S1", "RBD")]  # 特徵變量
y <- data$NT  # 目標變量
# 訓練控制，使用10折交叉驗證，並設置評估指標為 R-squared
control <- trainControl(method = "cv", number = 10, summaryFunction = defaultSummary)
# 搜索所有可用的回歸模型
models <- c("lm", "rpart", "rf", "svmRadial", "knn", "ridge", "lasso", "xgbLinear", "gbm","gam")
# 創建一個列表來存儲每個模型的結果
model_list <- list()
# 循環訓練每個模型，並同時調整超參數
for (model in models) {
print(paste("Training model:", model))
# 使用 tuneLength 設定進行自動調參
model_train <- train(x, y,
method = model,
trControl = control,
tuneLength = 5,  # 搜索最佳超參數
metric = "Rsquared")  # 使用 R-squared 作為評估指標
model_list[[model]] <- model_train
}
# 比較所有模型的結果
results <- resamples(model_list)
summary(results)
# 圖形化比較
dotplot(results)
#---------------------------------------------------------------------------------------------
# 檢查最佳的模型參數
for (model in names(model_list)) {
print(paste("Best parameters for model:", model))
print(model_list[[model]]$bestTune)
}
# 查看 R-squared 最高的模型
best_model <- model_list[[which.max(sapply(model_list, function(x) max(x$results$Rsquared)))]]
print(best_model)
# 使用最佳模型進行預測
predictions <- predict(best_model, newdata = x)
# 加載必要的庫
library(caret)
# 读取数据
data <- read.csv("/Users/benrio0923/Documents/計畫專案/NeuA ana/test/data.csv",
header = TRUE, sep = ',', encoding = 'UTF-8')
x <- data[, c("S1", "RBD")]  # 特徵變量
y <- data$NT  # 目標變量
# 訓練控制，使用10折交叉驗證，並設置評估指標為 R-squared
control <- trainControl(method = "cv", number = 5, summaryFunction = defaultSummary)
# 搜索所有可用的回歸模型
models <- c("lm", "rpart", "rf", "svmRadial", "knn", "ridge", "lasso", "xgbLinear", "gbm","gam")
# 創建一個列表來存儲每個模型的結果
model_list <- list()
# 循環訓練每個模型，並同時調整超參數
for (model in models) {
print(paste("Training model:", model))
# 使用 tuneLength 設定進行自動調參
model_train <- train(x, y,
method = model,
trControl = control,
tuneLength = 10,  # 搜索最佳超參數
metric = "Rsquared")  # 使用 R-squared 作為評估指標
model_list[[model]] <- model_train
}
# 比較所有模型的結果
results <- resamples(model_list)
summary(results)
# 圖形化比較
dotplot(results)
#---------------------------------------------------------------------------------------------
# 檢查最佳的模型參數
for (model in names(model_list)) {
print(paste("Best parameters for model:", model))
print(model_list[[model]]$bestTune)
}
# 查看 R-squared 最高的模型
best_model <- model_list[[which.max(sapply(model_list, function(x) max(x$results$Rsquared)))]]
print(best_model)
# 使用最佳模型進行預測
predictions <- predict(best_model, newdata = x)
# 載入必要的庫
library(readr)
library(glmnet)
library(caret)
# 讀取數據
data <- read_csv("data.csv")
# 準備訓練數據
X <- data[, c("S1", "RBD")]
y <- data$NT
# 將數據轉換為矩陣格式
X_matrix <- as.matrix(X)
# 設置交叉驗證
set.seed(123)
cv_folds <- createFolds(y, k = 5, returnTrain = FALSE)
# 使用交叉驗證來選擇最佳的lambda值
cv_fit <- cv.glmnet(X_matrix, y, alpha = 0, foldid = cv_folds)
# 使用最佳lambda訓練最終模型
best_lambda <- cv_fit$lambda.min
final_model <- glmnet(X_matrix, y, alpha = 0, lambda = best_lambda)
# 打印一些模型信息
print(paste("Best lambda:", best_lambda))
print(paste("Number of non-zero coefficients:", sum(coef(final_model) != 0)))
print("Model coefficients:")
print(coef(final_model))
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(caret)
library(doParallel)
library(xgboost)  # 確保載入 xgboost 套件
# Load data
data <- read.csv("data.csv")
# Set up parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
# Define training control with reduced CV folds and tuneLength
train_control <- trainControl(
method = "cv",
number = 10, # Reduce the number of cross-validation folds to speed up training
allowParallel = TRUE,
savePredictions = "final",
verboseIter = TRUE
)
# Initialize variable to store the best model
best_model <- NULL
best_rsq <- -Inf
# Attempt to train the model and handle interruptions
tryCatch({
# Train XGBoost Dart with reduced tuneLength
set.seed(123)
xgbdart_model <- train(
NT ~ S1 + RBD,
data = data,
method = "xgbDART",
trControl = train_control,
tuneLength = 10,
metric = "Rsquared",
maximize = TRUE
)
# Update the best model
current_best_rsq <- max(xgbdart_model$results$Rsquared, na.rm = TRUE)
if (current_best_rsq > best_rsq) {
best_rsq <- current_best_rsq
best_model <- xgbdart_model
}
}, interrupt = function(interrupt) {
message("Training was interrupted. Saving the current best model...")
}, error = function(e) {
message("An error occurred: ", e$message)
}, finally = {
if (!is.null(best_model)) {
saveRDS(best_model, "xgbdart_model.rds")
message("Best model saved as xgbdart_model.rds")
} else {
message("No model to save.")
}
# Stop parallel processing
stopCluster(cl)
registerDoSEQ()
})
library(caret)
library(doParallel)
# Load data
data <- read.csv("data.csv")
# Set up parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
# Define training control with reduced CV folds and tuneLength
train_control <- trainControl(
method = "cv",
number = 5, # 減少交叉驗證折數以加快訓練速度
allowParallel = TRUE,
savePredictions = "final",
verboseIter = TRUE
)
# Initialize variable to store the best model
best_model <- NULL
best_rsq <- -Inf
# 嘗試訓練模型並捕捉中斷
tryCatch({
# Train XGBoost Dart with reduced tuneLength
set.seed(123)
xgbdart_model <- train(
NT ~ S1 + RBD,
data = data,
method = "xgbDART",
trControl = train_control,
tuneLength = 5,
metric = "Rsquared",
maximize = TRUE
)
# 更新最佳模型
if (max(xgbdart_model$results$Rsquared) > best_rsq) {
best_rsq <- max(xgbdart_model$results$Rsquared)
best_model <- xgbdart_model
}
}, interrupt = function(interrupt) {
message("訓練過程被中斷，正在保存當前最佳模型...")
}, finally = {
if (!is.null(best_model)) {
saveRDS(best_model, "xgbdart_model.rds")
message("最佳模型已儲存為 xgbdart_model.rds")
}
# 停止並行處理
stopCluster(cl)
registerDoSEQ()
})
library(caret)
# Load data
data <- read.csv("data.csv")
# Define training control
train_control <- trainControl(method = "cv", number = 10)
# Train XGBoost Dart
set.seed(123)
xgbdart_model <- train(NT ~ S1 + RBD, data = data, method = "xgbDART",
trControl = train_control, tuneLength = 5)
library(caret)
# Load data
data <- read.csv("data.csv")
# Define training control
train_control <- trainControl(method = "cv", number = 10)
# Train XGBoost Dart
set.seed(123)
xgbdart_model <- train(NT ~ S1 + RBD, data = data, method = "xgbDART",
trControl = train_control, tuneLength = 5)
# Save the best model
saveRDS(xgbdart_model, "xgbdart_model.rds")
library(caret)
library(caret)
# 加載所有模型
lm_model <- readRDS("lm_model.rds")
rf_model <- readRDS("rf_model.rds")
gbm_model <- readRDS("gbm_model.rds")
glment_model <- readRDS("glment_model.rds")
xgbtree_model <- readRDS("xgbtree_model.rds")
svmlinear_model <- readRDS("svmlinear_model.rds")
gam_model <- readRDS("gam_model.rds")
gamspline_model <- readRDS("gamspline_model.rds")
earth_model <- readRDS("earth_model.rds")
xgblinear_model <- readRDS("xgblinear_model.rds")
xgbdart_model <- readRDS("xgbdart_model.rds")
# 提取最佳 R-squared
model_names <- c("Linear Model", "Random Forest", "GBM", "GLM Elastic Net",
"XGBoost Tree", "SVM Linear", "GAM", "GAM Spline",
"Earth (MARS)", "XGBoost Linear", "XGBoost Dart")
r_squared <- c(
max(lm_model$results$Rsquared),
max(rf_model$results$Rsquared),
max(gbm_model$results$Rsquared),
max(glment_model$results$Rsquared),
max(xgbtree_model$results$Rsquared),
max(svmlinear_model$results$Rsquared),
max(gam_model$results$Rsquared),
max(gamspline_model$results$Rsquared),
max(earth_model$results$Rsquared),
max(xgblinear_model$results$Rsquared),
max(xgbdart_model$results$Rsquared)
)
# 創建表格
performance_table <- data.frame(
Model = model_names,
R_Squared = r_squared
)
# 顯示表格
print(performance_table)
# 保存表格為 CSV
write.csv(performance_table, "model_performance.csv", row.names = FALSE)
xgbdart_model
runApp()
runApp()
runApp()
runApp()
install.packages("KRLS")
runApp()
runApp()
runApp('~/Documents/計畫專案/NeuA ana/UI version/3.0 20240919')
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
install.packages("networkD3", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
# 載入必要的套件
library(dplyr)
# 建立模擬的BLAST數據框
blast_data <- data.frame(
query_id = c("Q1", "Q2", "Q3", "Q4"),
subject_id = c("S1", "S2", "S3", "S4"),
taxonomy = c("Bacteria", "Archaea", "Fungi", "Virus"),
evalue = c(1e-5, 1e-20, 1e-10, 1e-25),
method = "BLAST"
)
# 建立模擬的DIAMOND數據框
diamond_data <- data.frame(
query_id = c("Q1", "Q5", "Q6", "Q7"),
subject_id = c("S1", "S5", "S6", "S7"),
taxonomy = c("Bacteria", "Protista", "Fungi", "Virus"),
evalue = c(1e-15, 1e-30, 1e-8, 1e-12),
method = "DIAMOND"
)
# 查看模擬資料
print(blast_data)
print(diamond_data)
# 合併BLAST和DIAMOND的資料
combined_data <- bind_rows(blast_data, diamond_data)
# 查看合併後的資料
print(combined_data)
# 匯入CSV格式的BLAST和DIAMOND資料
blast_data <- read.csv("blast_results.csv")
# 合併BLAST和DIAMOND的資料
combined_data <- bind_rows(blast_data, diamond_data)
# 查看合併後的資料
print(combined_data)
# 為每個資料集加上method欄位
blast_data$method <- "BLAST"
diamond_data$method <- "DIAMOND"
# 合併兩份數據
combined_data <- bind_rows(blast_data, diamond_data)
# 查看合併後的資料
head(combined_data)
# 載入繪圖套件
library(ggplot2)
# 繪製E值分佈的簡單示例
ggplot(combined_data, aes(x = taxonomy, y = -log10(evalue), fill = method)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "BLAST vs DIAMOND E-value Comparison", x = "Taxonomy", y = "-log10(E-value)") +
theme_minimal()
# 建立包含所有分類層級和方法的節點清單
nodes <- data.frame(name = unique(c(combined_data$method, combined_data$taxonomy)))
# 計算每個分類層級和方法的命中數量
links <- combined_data %>%
group_by(method, taxonomy) %>%
summarise(hit_count = n()) %>%
ungroup()
# 將method和taxonomy對應到節點index
links$source <- match(links$method, nodes$name) - 1
links$target <- match(links$taxonomy, nodes$name) - 1
links$value <- links$hit_count
# 為不同的方法設置顏色
links$color <- ifelse(links$method == "BLAST", "rgba(0, 128, 255, 0.7)", "rgba(255, 128, 0, 0.7)")
# 繪製Sankey Diagram
sankeyNetwork(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
units = "hits", fontSize = 12, nodeWidth = 30,
colourScale = JS("d3.scaleOrdinal().domain(['BLAST', 'DIAMOND']).range(['#007FFF', '#FF7F00'])"),
LinkGroup = "color")
library(networkD3)
# 建立包含所有分類層級和方法的節點清單
nodes <- data.frame(name = unique(c(combined_data$method, combined_data$taxonomy)))
# 計算每個分類層級和方法的命中數量
links <- combined_data %>%
group_by(method, taxonomy) %>%
summarise(hit_count = n()) %>%
ungroup()
# 將method和taxonomy對應到節點index
links$source <- match(links$method, nodes$name) - 1
links$target <- match(links$taxonomy, nodes$name) - 1
links$value <- links$hit_count
# 為不同的方法設置顏色
links$color <- ifelse(links$method == "BLAST", "rgba(0, 128, 255, 0.7)", "rgba(255, 128, 0, 0.7)")
# 繪製Sankey Diagram
sankeyNetwork(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
units = "hits", fontSize = 12, nodeWidth = 30,
colourScale = JS("d3.scaleOrdinal().domain(['BLAST', 'DIAMOND']).range(['#007FFF', '#FF7F00'])"),
LinkGroup = "color")
# 建立BLAST模擬資料，有相同的query但不同的subject
blast_data <- data.frame(
query_id = c("Q1", "Q1", "Q2", "Q2", "Q3"),
subject_id = c("S1", "S2", "S3", "S4", "S5"),
taxonomy = c("Bacteria", "Fungi", "Archaea", "Protista", "Virus"),
evalue = c(1e-5, 1e-10, 1e-20, 1e-15, 1e-25),
method = "BLAST"
)
# 建立DIAMOND模擬資料，也包含相同的query但不同的subject
diamond_data <- data.frame(
query_id = c("Q1", "Q1", "Q2", "Q3", "Q3"),
subject_id = c("S6", "S7", "S8", "S9", "S10"),
taxonomy = c("Virus", "Bacteria", "Archaea", "Fungi", "Protista"),
evalue = c(1e-8, 1e-12, 1e-30, 1e-18, 1e-5),
method = "DIAMOND"
)
# 查看模擬的BLAST和DIAMOND資料
print(blast_data)
print(diamond_data)
library(networkD3)
# 合併BLAST和DIAMOND的資料
combined_data <- bind_rows(blast_data, diamond_data)
# 建立包含所有分類層級和方法的節點清單
nodes <- data.frame(name = unique(c(combined_data$method, combined_data$taxonomy)))
# 計算每個分類層級和方法的命中數量
links <- combined_data %>%
group_by(method, taxonomy) %>%
summarise(hit_count = n()) %>%
ungroup()
# 將method和taxonomy對應到節點index
links$source <- match(links$method, nodes$name) - 1
links$target <- match(links$taxonomy, nodes$name) - 1
links$value <- links$hit_count
# 為不同的方法設置顏色
links$color <- ifelse(links$method == "BLAST", "rgba(0, 128, 255, 0.7)", "rgba(255, 128, 0, 0.7)")
# 繪製Sankey Diagram
sankeyNetwork(Links = links, Nodes = nodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
units = "hits", fontSize = 12, nodeWidth = 30,
colourScale = JS("d3.scaleOrdinal().domain(['BLAST', 'DIAMOND']).range(['#007FFF', '#FF7F00'])"),
LinkGroup = "color")
shiny::runApp('git-my-repo/CatTrees')
Sys.setenv(PKG_CONFIG_PATH = "/opt/homebrew/opt/openssl@3/lib/pkgconfig")
install.packages("PKI", type = "source")
install.packages("PKI", type = "source")
Sys.setenv(PKG_CONFIG_PATH = "/opt/homebrew/opt/openssl@3/lib/pkgconfig")
install.packages("PKI", type = "source")
install.packages("PKI", type = "source",
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl/include" LDFLAGS="-L/opt/homebrew/opt/openssl/lib"')
install.packages("PKI", type = "source",
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl/include" LDFLAGS="-L/opt/homebrew/opt/openssl/lib"')
install.packages("PKI", type = "source",
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl@3/include" LDFLAGS="-L/opt/homebrew/opt/openssl@3/lib"')
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl@3/include" LDFLAGS="-L/opt/homebrew/opt/openssl@3/lib"')
install.packages("PKI", type = "source",
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl@3/include" LDFLAGS="-L/opt/homebrew/opt/openssl@3/lib"')
install.packages("PKI", type = "source",
configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl@3/include" LDFLAGS="-L/opt/homebrew/opt/openssl@3/lib"')
install.packages("PKI", type = "source")
install.packages("PKI", type = "source")
install.packages("PKI", type = "source",configure.vars = 'CPPFLAGS="-I/opt/homebrew/opt/openssl@3/include" LDFLAGS="-L/opt/homebrew/opt/openssl@3/lib"')
install.packages("PKI", type = "source")
install.packages("PKI", type = "source")
shiny::runApp('git-my-repo/CatTrees')
runApp('git-my-repo/CatTrees')
runApp('git-my-repo/CatTrees')
install.packages("optparse")
shiny::runApp('git-my-repo/CatTrees')
